import os
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torchvision import transforms
from PIL import Image
from tqdm import tqdm
#from models.TransUnet import TransUNetV2
from models.transunet_v2_localvit_final_fixed_v6_fixed import TransUNetV2
from utils.metrics_gray import dice_score, iou_score, hd95

# Êï∞ÊçÆÈõÜÂÆö‰πâ
class ThyroidDataset(Dataset):
    def __init__(self, image_paths, label_paths, transform=None):
        self.image_paths = image_paths
        self.label_paths = label_paths
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert("L")
        label = Image.open(self.label_paths[idx]).convert("L")

        if self.transform:
            image = self.transform(image)
            label = self.transform(label)

        return image, label

def get_file_list(img_dir, label_dir, total):
    images = []
    labels = []
    for i in range(total):
        img_name = f"train_img_{i:04d}.png"
        label_name = f"train_label_{i:04d}.png"
        if i < 500:
            images.append(os.path.join(img_dir, "labeled", img_name))
        else:
            images.append(os.path.join(img_dir, "unlabeled", img_name))
        labels.append(os.path.join(img_dir, "labels", label_name))
    return images, labels

# È™åËØÅÈõÜ
def get_val_dataset(val_dir, transform):
    val_img_dir = os.path.join(val_dir, "images")
    val_label_dir = os.path.join(val_dir, "labels")
    val_images = sorted([os.path.join(val_img_dir, f) for f in os.listdir(val_img_dir)])
    val_labels = sorted([os.path.join(val_label_dir, f) for f in os.listdir(val_label_dir)])
    return ThyroidDataset(val_images, val_labels, transform)

# ÂèÇÊï∞ËÆæÁΩÆ
IMG_SIZE = 224
BATCH_SIZE = 4
NUM_EPOCHS = 50
LR = 3e-4
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

# Ë∑ØÂæÑËÆæÁΩÆ
train_root = "/data16t/sihan/DDT/data/image/train"
#val_root = "data/image/val"
val_root = "/data16t/sihan/DDT/data/image/val"

# Êï∞ÊçÆÂ¢ûÂº∫
transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor(),
])

# Âä†ËΩΩËÆ≠ÁªÉÈõÜ
train_imgs, train_labels = get_file_list(train_root, train_root, total=2500)
train_dataset = ThyroidDataset(train_imgs, train_labels, transform=transform)
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)

# Âä†ËΩΩÈ™åËØÅÈõÜ
val_dataset = get_val_dataset(val_root, transform)
val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False)

# Ê®°Âûã„ÄÅÊçüÂ§±„ÄÅ‰ºòÂåñÂô®
#model = TransUNetV2(img_size=IMG_SIZE, in_channels=1, num_classes=1).to(DEVICE)
model = TransUNetV2(
    img_size=224,
    in_channels=1,
    num_classes=1,
    vit_weights="/data16t/sihan/DDT/weights/vit_base_patch16_224.pth"  # ÊõøÊç¢‰∏∫‰Ω†ÁöÑÂÆûÈôÖË∑ØÂæÑ
    #vit_weights=None
).to(DEVICE)

criterion = nn.BCEWithLogitsLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=LR)

# ËÆ≠ÁªÉÂæ™ÁéØ
for epoch in range(NUM_EPOCHS):
    model.train()
    total_loss = 0
    pbar = tqdm(train_loader, desc=f"[Epoch {epoch+1}/{NUM_EPOCHS}] Training")
    for imgs, masks in pbar:
        imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)
        print("imgs shape:", imgs.shape)
        outputs = model(imgs).squeeze(1)
        masks = masks.squeeze(1)
        loss = criterion(outputs, masks)

        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

        total_loss += loss.item()
        pbar.set_postfix(loss=loss.item())

    print(f"‚úÖ Epoch {epoch+1} Training Loss: {total_loss/len(train_loader):.4f}")

    # È™åËØÅÈò∂ÊÆµ
    model.eval()
    dices, ious, hd95s = [], [], []
    with torch.no_grad():
        for imgs, masks in val_loader:
            imgs, masks = imgs.to(DEVICE), masks.to(DEVICE)
            outputs = model(imgs).squeeze(1)
            masks = masks.squeeze(1)

            preds = torch.sigmoid(outputs)
            dices.append(dice_score(preds, masks))
            ious.append(iou_score(preds, masks))
            hd95s.append(hd95(preds.unsqueeze(1), masks.unsqueeze(1)))

    print(f"üîç Val Dice: {sum(dices)/len(dices):.4f}, IoU: {sum(ious)/len(ious):.4f}, HD95: {sum(hd95s)/len(hd95s):.2f}")

# ‰øùÂ≠òÊ®°Âûã
# os.makedirs("checkpoints", exist_ok=True)
# torch.save(model.state_dict(), "checkpoints/transunetv2_pretrained_full2500_with_val.pth")
# print("‚úÖ ÂæÆË∞ÉÂÆåÊàêÔºåÊ®°ÂûãÂ∑≤‰øùÂ≠òÂà∞ checkpoints/transunetv2_pretrained_full2500_with_val.pth")
os.makedirs("/data16t/sihan/DDT/outputs/checkpoints", exist_ok=True)
torch.save(model.state_dict(), "/data16t/sihan/DDT/outputs/checkpoints/transunetv2_pretrained_full2500_with_val.pth")
print("‚úÖ ÂæÆË∞ÉÂÆåÊàêÔºåÊ®°ÂûãÂ∑≤‰øùÂ≠òÂà∞ /data16t/sihan/DDT/outputs/checkpoints/transunetv2_pretrained_full2500_with_val.pth")
